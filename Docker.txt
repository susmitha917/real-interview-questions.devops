1.What is a Dockerfile?

A Dockerfile is a script containing a series of instructions on how to build a Docker image. Each instruction in a Dockerfile creates a layer in the image, 
and these layers are stacked to form the final image. Declarative way of creating custom images.

2.What is multi-stage in Docker?

Multi-stage builds in Docker allow you to use multiple FROM statements in your Dockerfile to create smaller, more efficient images. This approach helps in 
separating the build environment from the final runtime environment, significantly reducing the size of the final image. Multi-stage builds are particularly 
useful for applications that require a heavy build process but a lightweight runtime environment.

# Build Stage
FROM golang:1.18 AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp

# Final Stage
FROM alpine:latest
WORKDIR /app
COPY --from=builder /app/myapp .
ENTRYPOINT ["./myapp"]



3.What is a Docker volume and how do you use it?

A Docker volume is a storage mechanism used to persist data generated by and used by Docker containers. Volumes are managed by Docker and are independent of the
 container lifecycle, meaning they can persist data even if the container is deleted. They are the preferred mechanism for persisting data in Docker containers 
 because they offer several advantages over other storage options like bind mounts or storage within the container's filesystem.

volumes
------------
containers are ephemeral by default, once you remove the container it will remove the data also..
1. unnamed volumes. create a directory in linux and mount to container using -v host-path:container-path
2. named volumes
 
1. Named Volumes
Named volumes are explicitly created and managed by Docker. They are stored in Docker's default location on the host and can be shared 
among multiple containers.

2. Anonymous Volumes
Anonymous volumes are not given a specific name. They are useful for scenarios where you need a temporary volume that you don’t need to reference later. 
These volumes are automatically created and removed when the container is removed.


4.How can we pass an argument to Dockerfile?
Passing arguments to a Dockerfile can be done using the ARG instruction to define build-time variables and the --build-arg flag with the docker build 
command to pass values for those variables.

Using ARG in Dockerfile
The ARG instruction is used to define a variable that users can pass at build-time to the Dockerfile.






5.Dockerfile runs as which user?

By default, Docker runs all instructions in a Dockerfile as the root user. This means that unless explicitly changed, the commands in the Dockerfile are 
executed with root privileges, which can pose security risks. It is often a good practice to switch to a non-root user for running applications within the 
container to minimize these risks.

How to Specify a Different User
You can use the USER instruction in the Dockerfile to specify a different user under which the subsequent instructions will be executed. Here's how you can do it:

Create a new user: Use the RUN instruction to add a new user.
Switch to the new user: Use the USER instruction to switch to the newly created user.









6.How do you push the image to Docker Hub?


Pushing an image to Docker Hub involves several steps:

Log in to Docker Hub
Tag the image
Push the image

7.Write a Dockerfile for a Java-based application?


# Use an official OpenJDK runtime as a parent image
FROM openjdk:17-jdk-slim

# Set the working directory in the container
WORKDIR /app

# Copy the application JAR file into the container
COPY target/app.jar /app/app.jar

# Define environment variables
ENV APP_ENV=production
ENV DB_URL=jdbc:mysql://localhost:3306/mydb

# Expose port 8080 (or any other port your application uses)
EXPOSE 8080

# Define the command to run your application
CMD ["java", "-jar", "app.jar"]

8.What is Docker Compose?

Docker Compose is a tool for defining and running multi-container Docker applications. It allows you to configure your application's services, networks, and 
volumes in a single file called docker-compose.yml and then manage the entire application lifecycle with simple commands.


9.How is Docker integrated in Jenkins?

Docker is integrated into Jenkins primarily through plugins that allow Jenkins to interact with Docker containers. This integration enhances Jenkins' 
capabilities by enabling it to build, run, and manage Docker containers as part of its automation workflows.

Docker in Pipelines: Using the Docker Pipeline plugin or direct Docker commands, Jenkins can build, test, and deploy Docker images within pipeline scripts.


10.Please explain Docker networking.

Docker networking allows containers to communicate with each other and the outside world using different network types like bridge, host, overlay, and more. It 
provides isolation, security, and flexibility to connect containers based on specific application needs and deployment scenarios.

Bridge Network
Default Network: Used when no other network is specified.
Isolation: Containers on the same bridge can communicate with each other but are isolated from external networks.
Use Case: Suitable for simple, single-host setups.

Host Network
Shared Network: Containers use the host’s network stack, sharing the host's IP and ports.
Performance: Offers better network performance due to no namespace overhead.
Use Case: Suitable for high-performance applications that need direct access to the host network.

Overlay Network
Multi-Host Network: Allows containers to communicate across different Docker hosts.
Swarm Mode: Commonly used in Docker Swarm for multi-host communication.
Use Case: Suitable for distributed applications requiring secure communication between containers on different hosts.




11.Can you use multiple FROM statements in a Dockerfile?

Yes, you can use multiple FROM statements in a Dockerfile. This is a feature of multi-stage builds, which allows you to create more complex Docker images by 
building different parts of your application in separate stages. Multi-stage builds are especially useful for optimizing the size of the final Docker image and 
for separating build dependencies from runtime dependencies.It allows you to separate build dependencies from runtime dependencies and to minimize the size of 
your final Docker images.


12.What is the difference between RUN and CMD?

RUN: Used to build the image, execute commands at build time, and create new image layers.
CMD: Sets the default command to run at container start time and can be overridden.

RUN vs CMD
-----------
RUN --> executes at build time means image creation time
CMD --> only executes at the time of container creation i.e docker run

COPY vs ADD
-------------
COPY and ADD both are to copy the files from workspace to docker image. but ADD have 2 extra advantages
1. It can directly download content from internet into the image
2. It can directly untart the files into the image.


13.Write a Dockerfile for an Nginx application.

# Use the official Nginx base image
FROM nginx:latest
from should be the first instruction to represent base os
FROM image-name:tag

# Set the working directory to /usr/share/nginx/html
WORKDIR /usr/share/nginx/html

# Copy the current directory contents into the container at /usr/share/nginx/html
COPY . .

# Expose port 80 to the outside world
EXPOSE 80

# Start Nginx when the container launches
CMD ["nginx", "-g", "daemon off;"]


14.What is the difference between Docker images and Docker containers?

Docker Images
Definition:
A Docker image is a read-only template that contains the application code, libraries, dependencies, tools, and other files needed to run an application.

Immutability:
Docker images are immutable, meaning they do not change once they are created. Any changes require creating a new image.
Layers:
Docker images are composed of layers. Each layer represents a set of file changes or additions. Layers are created by executing Dockerfile instructions 
(e.g., RUN, COPY, ADD).
Storage:
Docker images are stored in Docker registries (e.g., Docker Hub, private registries) from where they can be downloaded and shared.
Usage:
Docker images are used to create Docker containers. They provide the blueprint for what the container should contain and how it should run.
Build:
Docker images are built using a Dockerfile, which contains a series of instructions to set up the environment and application.


Docker Containers
Definition:

A Docker container is a runnable instance of a Docker image. It is a lightweight, standalone, and executable package that includes everything needed to run the 
application.

Mutable State:
Unlike images, containers can have a mutable state. They can be started, stopped, moved, and deleted. You can also make changes inside a running container.

Isolation:
Containers provide process and filesystem isolation using Linux kernel features like namespaces and cgroups. Each container runs in its own isolated environment.

Lifecycle:
Containers have a lifecycle: they can be created, started, stopped, paused, restarted, and removed.

Storage:
Containers can use volumes or bind mounts to persist data beyond their lifecycle. Without these, changes made to a container are lost when it is removed.

Usage:
Containers are used to run applications based on the blueprint provided by the image. Multiple containers can be run from the same image, each with its own 
unique state and data.




15.What are the benefits and use cases of using multi-stage builds in Docker?

Multi-stage builds in Docker offer several benefits, including reduced image size, enhanced security, improved build efficiency, simplified Dockerfiles, 
and reusability of intermediate stages. They are particularly useful in scenarios involving complex build processes, optimizing build and runtime environments, 
and improving the overall efficiency and security of Docker images.


16.How does Docker handle resource limitations and isolation, such as CPU, memory, and I/O?

Docker handles resource limitations and isolation using cgroups(control groups) for resource control and namespaces for isolation. These mechanisms ensure that 
containers run 
efficiently, securely, and independently from each other. By setting appropriate resource limits, you can prevent any single container from consuming too many 
resources and affecting the performance or stability of other containers or the host system.



17.Docker command: COPY vs ADD.

Use COPY whenever you simply need to copy files and directories from the host to the Docker image. It is clearer and more secure.
Use ADD only when you need the extra functionality it provides, such as automatically extracting compressed files or fetching remote files. Be mindful of the 
potential security implications when using URLs.



18.ENTRYPOINT vs CMD in Dockerfile.

CMD
Purpose: CMD is used to provide default arguments for the ENTRYPOINT command or to specify the default command that should run when the container starts.

ENTRYPOINT: Cannot be overridden as easily. The command will always be executed, but you can override the arguments by passing them when running the container.
ENTRYPOINT: Specifies a command that always runs. It is useful for creating containers with a specific purpose, where CMD can provide default arguments.

CMD instruction can be overriden
same instruction trying to override with ENTRYPOINT is not working
you can mix CMD and entrypoint for better results
you can't override ENTRYPOINT, if you try to do it will go append
ping -c5
CMD is used to supply default arguements to ENTRYPOINT, we can always override default args from runtime.


19.what is docker?
Docker is a platform that enables developers to create, deploy, and manage applications within containers. Containers are lightweight, portable, and self-sufficient 
units that include everything needed to run an application: code, runtime, system tools, libraries, and settings. Here are some key aspects of Docker:

Containerization: Docker packages applications and their dependencies into containers, ensuring that they run consistently across different environments, 
from development to production.





INSTRUCTIONS:
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1. FROM
The FROM instruction sets the base image for subsequent instructions in the Dockerfile. It must be the first instruction in the Dockerfile.
ex: FROM ubuntu:20.04
from should be the first instruction to represent base os
FROM image-name:tag

2. RUN
The RUN instruction executes any commands in a new layer on top of the current image and commits the results.
Ex: RUN apt-get update && apt-get install -y nginx
We wil use RUN instruction to install packages and configure them. RUN instruction wll execute at the time of image creation.


3. ADD
The ADD instruction copies new files, directories, or remote file URLs from <src> and adds them to the filesystem of the image at the path <dest>. 
It can also unpack compressed files.
Ex:ADD myapp.tar.gz /usr/src/app


4. ARG
The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command.
1. ARG can be first instruction in only one case. It can be used to supply the version for FROM instruction
2. You can have args in Dockerfile, you can supply the values through command through option --build-args
3. You can always have default values to arg and override if required.
Ex:ARG build_version
RUN echo "Building version ${build_version}"

ENV vs ARG
-----------
1. ENV variables can be accessed both at the time build time and containers
2. ARG instruction can only be accessed at the time of build or image

5. CMD
The CMD instruction provides defaults for an executing container. These defaults can include an executable, or they can omit the executable, 
in which case you must specify an ENTRYPOINT instruction as well.
Ex:CMD ["nginx", "-g", "daemon off;"]
this instruction will run at the time of container creation.


6. COPY
The COPY instruction copies new files or directories from <src> and adds them to the filesystem of the container at the path <dest>. It only supports local 
files.
Ex:COPY . /usr/src/app

7. ENTRYPOINT
The ENTRYPOINT instruction allows you to configure a container that will run as an executable.
Ex:ENTRYPOINT ["python", "app.py"]


8. ENV
The ENV instruction sets the environment variable <key> to the value <value>.
Ex:ENV PORT=8080

9. EXPOSE
The EXPOSE instruction informs Docker that the container listens on the specified network ports at runtime.
Ex:EXPOSE 80

expose instruction will let the users know what are the ports used by image/container


10. LABEL
The LABEL instruction adds metadata to an image. A label is a key-value pair.
Ex:LABEL version="1.0"

11. ONBUILD
The ONBUILD instruction adds a trigger instruction to the image that will be executed when the image is used as the base for another build.
this is useful as a trigger, if some one is trying to use your image. you can force them to keep somefiles in their workspace or some configuration
Ex:ONBUILD COPY . /app/src

12. USER
The USER instruction sets the UID (or username) to use when running the image and for any RUN, CMD, and ENTRYPOINT instructions that follow it in the Dockerfile.
Ex:USER nginx


13. WORKDIR
The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY, and ADD instructions that follow it in the Dockerfile.
Ex:WORKDIR /usr/src/app




KEYPOINTS:
-----------------------------------------------------------------------
Microservices == Containersation
-------------------
You install containersation in VM, Container dont block the resources..

containers can get the resources dynamically. They dont block resources...

resource utilisation is very high
booting time is verrrrry less - may be in sec

portability

AMI --> take one full OS, create VM, install application runtime(Java,NodeJs, python, DotNet), configuration(creation of users, foldres, permissions, etc).download code, run the service

take AMI out of this

Docker image == Bare minimum OS + App run time + system pacakges and dependencies + App code = Image
Bare minimum OS --> no unnecessary pacakges --> no cat comman also

Container
AMI --> Static file
EC2 instance --> if you run AMI, it can create instance --> Running version of AMI is called instance
Docker image --> static file
Docker container --> running instance of image is called container
install docker --> it will create a group called docker
users who are in docker group or root user can only run docker commands...
usermod -aG docker <user-name>
docker images --> list donw the images

docker pull nginx
group id, artifact id and version
username, image name and version 
joindevops/catalogue:1.0.0
nginx --> Bare minimum OS (ubuntu/Centos/debian/rhel)+nginx 
nginx:alpine --> Alpine is OS which is max 10MB
docker create <image>:tag --> this will create container
docker ps --> it will show running containers
docker ps -a --> all containers with any status
docker start <CID> --> container will start running
docker run = docker pull + docker create + docker run
docker rmi `docker images -a -q`
docker rm `docker ps -a -q`

How can you access docker container from internet?

By enabling the port, we need to open host port that can redirect traffic to container..

docker run -d -p <host-port>:<container-port> nginx

ADVATNAGES:
VMs: Full OS per instance, heavier, slower to start, more resource-intensive.
Containers: Share host OS, lighter, faster to start, less resource-intensive.

How to get the terminal access of running container?
docker exec -it container-id bash or docker exec -it <container-id or container-name> /bin/bash


docker inspect container-id/image-id: is used to retrieve detailed information about a Docker container or image.
docker logs

Dockerfile -->it is the declarative way of creating custom images
Shell --> keep all the commands in a file and run it...
Dockerfile --> keep all the instructions a file i.e Dockerfile and build the image.
Docker image = BaseOS+ App run time+ system packages and application dependencies + app code
docker build -t url/username/image-name:tag . --> will check for Dockerfile

docker build -t myregistry.com/myuser/myapp:1.0 .

This command builds a Docker image using the Dockerfile in the current directory, tags it as myregistry.com/myuser/myapp:1.0, and makes it ready for pushing 
to a Docker registry at myregistry.com.


How can you push the image to docker-hub
-----------------------------------------
url/username/image-name:tag
you can push images to docker hub, nexus, ECR, jfrog,etc.
url=docker.io
First, ensure you're logged in to your Docker Hub account. Use the following command to log in
docker login
You'll be prompted to enter your Docker Hub username and password.
2. Tag the Image:
docker tag <local-image-name> <dockerhub-username>/<repository-name>:<tag>

<local-image-name>: The name or ID of the image you want to push.                         
<dockerhub-username>: Your Docker Hub username.
<repository-name>: The name of your repository on Docker Hub.
<tag>: The tag for the image (e.g., latest, v1.0).
Example:docker tag my-app-image dockerhub-username/my-app:latest
3. Push the Image:
docker push dockerhub-username/my-app:latest

Summary of commands:
docker login
docker tag my-app-image dockerhub-username/my-app:latest
docker push dockerhub-username/my-app:latest

docker create network expense
After creating the network, you can run containers attached to this network:
docker run -d  -p 8080:8080 --name backend --network expense backend

layer1 --> FROM nginx
layer2 --> FROM nginx+RUN rm -rf /usr/share/nginx/html/index.html --> create image

create layer2 container from layer2 image

layer3 image = layer2+RUN rm -rf /etc/nginx/nginx.conf

create layer3 container from layer3 image

layer4 image=layer3+RUN rm -rf /etc/nginx/conf.d/default.conf


usermod -aG docker ec2-user

FROM node:20.15.0-alpine3.20
EXPOSE 8080
ENV DB_HOST=mysql
RUN addgroup -S expense && adduser -S expense -G expense \
    && mkdir /opt/server \
    && chown expense:expense -R /opt/server
WORKDIR /opt/server
COPY package.json .
COPY *.js /opt/server/
RUN npm install
USER expense
EXPOSE 8081
CMD [ "node","index.js" ]


name: expense
networks:
  default:
    name: expense
volumes:
  mysql:
    #external: true # if true, you need to create manually
       # docker volume create myqsl
services:
  mysql:
    #image: mysql:v1.0
    image: susmitha925/mysql:v1.0
    container_name: mysql # --name mysql
    environment:
      - MYSQL_ROOT_PASSWORD=ExpenseApp@1
      - MYSQL_USER=expense
      - MYSQL_PASSWORD=ExpenseApp@1
      - MYSQL_DATABASE=transactions
    volumes:
    - source: mysql
      target: /var/lib/mysql
      type: volume # -v volume-name:/path/in/container
  backend:
    #image: backend:v1.0
    image: susmitha925/backend:v1.0
    container_name: backend
    command: sh -c "sleep 20 && node /opt/server/index.js"
    depends_on: 
    - mysql
  frontend:
    #image: frontend:v1.0
    image: susmitha925/frontend:v1.0
    container_name: frontend
    depends_on:
    - backend
    ports:
    - "80:80"
	
	
DOCKER BEST PRACTICES IN OUR PROJECT:
--------------------------------------------------------
use official images
use miultistage builds
keep the image size low
dont run container with root access
keep the env seperate from code
maintain seperate network
create docker volumes
layer optimization
     -club the multiple instructions at one place
	 -keep the frequent changes at the end.
	 
	 
	 
CONTAINER VS VIRTUAL MACHINES:
Containers:
Lightweight: Share the host OS kernel; minimal overhead.
Isolation: Process-level isolation; less secure.
Startup Time: Fast (seconds).
Resource Usage: Efficient; uses less memory and storage.
Use Case: Microservices, scalable applications.

Virtual Machines (VMs):
Heavyweight: Includes a full OS with its own kernel.
Isolation: Full OS-level isolation; more secure.
Startup Time: Slower (minutes).
Resource Usage: Higher; requires more memory and storage.
Use Case: Running different OSs, legacy applications, full isolation.

CONTAINER VS IMAGE:

Container:
Running Instance: A live, executable instance of an image.
Mutable: Can have changes during runtime (e.g., files created or modified).
Purpose: Runs applications or services.

Image:
Static Template: A read-only template with the application code, libraries, and dependencies.
Immutable: Cannot be changed after creation.
Purpose: Used to create containers.